{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from collections import namedtuple\n",
    "import random\n",
    "from typing import Callable\n",
    "from copy import deepcopy\n",
    "from itertools import accumulate\n",
    "from operator import xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nimply = namedtuple(\"Nimply\", \"row, num_objects\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Nim:\n",
    "    def __init__(self, num_rows: int, k: int = None) -> None:\n",
    "        self._rows = [i * 2 + 1 for i in range(num_rows)]\n",
    "        self._k = k\n",
    "        self._active_rows = [i for i in range(num_rows)]\n",
    "\n",
    "    def __bool__(self):\n",
    "        return sum(self._rows) > 0\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"<\" + \" \".join(str(_) for _ in self._rows) + \">\"\n",
    "\n",
    "    @property\n",
    "    def rows(self) -> tuple:\n",
    "        return tuple(self._rows)\n",
    "\n",
    "    @property\n",
    "    def k(self) -> int:\n",
    "        return self._k\n",
    "\n",
    "    def active_rows(self) -> list:\n",
    "        return self._active_rows\n",
    "\n",
    "    def nimming(self, ply: Nimply) -> None:\n",
    "        row, num_objects = ply\n",
    "        assert self._rows[row] >= num_objects\n",
    "        assert self._k is None or num_objects <= self._k\n",
    "        self._rows[row] -= num_objects\n",
    "        if self._rows[row] == 0:\n",
    "            self._active_rows.remove(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def optimal_strategy(board: Nim) -> Nimply: \n",
    "    *_, X = accumulate(board.rows, xor)\n",
    "\n",
    "    row_count = -1\n",
    "    for row in board.rows:\n",
    "        row_count += 1\n",
    "        if row > 0:\n",
    "            result = X ^ row\n",
    "            if result < row:\n",
    "                return Nimply(row_count, row - result)\n",
    "    return pure_random(board)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "\n",
    "strategy = (optimal_strategy, optimal_strategy)\n",
    "\n",
    "nim = Nim(11)\n",
    "logging.debug(f\"status: Initial board  -> {nim}\")\n",
    "player = 0\n",
    "while nim:\n",
    "    ply = strategy[player](nim)\n",
    "    nim.nimming(ply)\n",
    "    logging.debug(f\"status: After player {player} -> {nim}\")\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "logging.info(f\"status: Player {winner} won!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rules: \n",
    "    def __init__(self, board, rule_1, rule_2, rule_3, rule_4):\n",
    "        max_leave_nim_size = (len(board.rows) - 1) * 2\n",
    "\n",
    "        self.rules = {}\n",
    "\n",
    "        # How many elements to leave from the only active row\n",
    "        if rule_1 <= max_leave_nim_size:\n",
    "            self.rules['rule_1'] = rule_1\n",
    "        else:\n",
    "            self.rules['rule_1'] = random.randint(0, max_leave_nim_size)\n",
    "        \n",
    "        # How many elements to leave from the selected row of the two active rows,\n",
    "        # where one row has only 1 element left\n",
    "        if rule_2[1] <= max_leave_nim_size:\n",
    "            self.rules['rule_2'] = rule_2\n",
    "        else:\n",
    "            self.rules['rule_2'] = (random.randint(0, 1), random.randint(0, max_leave_nim_size))\n",
    "\n",
    "        # How many elements to leave from the selected row of the two active rows, \n",
    "        # where both rows have more than 1 element left\n",
    "        if rule_3[1] <= max_leave_nim_size:\n",
    "            self.rules['rule_3'] = rule_3\n",
    "        else:\n",
    "            self.rules['rule_3'] = (random.randint(0,1), random.randint(0, max_leave_nim_size))\n",
    "\n",
    "        # If there are more than two rows left, leave x elements from a random row\n",
    "        if rule_4 <= max_leave_nim_size:\n",
    "            self.rules['rule_4'] = rule_4\n",
    "        else:\n",
    "            self.rules['rule_4'] = random.randint(0, max_leave_nim_size)\n",
    "\n",
    "    def get_params(self):\n",
    "        return self.rules\n",
    "\n",
    "    def __feasability__(self, x, number_of_elements, row_index):\n",
    "        if number_of_elements - 1 >= x:\n",
    "            return Nimply(row_index, number_of_elements - x)\n",
    "        else:\n",
    "            return Nimply(row_index, 1)\n",
    "    \n",
    "    def set_rule_1(self, val):\n",
    "        self.rules['rule_1'] = val\n",
    "\n",
    "    def set_rule_2(self, val):\n",
    "        row, _ = self.rules['rule_2']\n",
    "        self.rules['rule_2'] = (row, val)\n",
    "\n",
    "    def set_rule_3(self, val):\n",
    "        row, _ = self.rules['rule_3']\n",
    "        self.rules['rule_3'] = (row, val)\n",
    "\n",
    "    def set_rule_4(self, val):\n",
    "        self.rules['rule_4'] = val\n",
    "\n",
    "    # If there is only 1 active row left, leave x elements in that row\n",
    "    def rule_1(self, board):\n",
    "        # Obtain the last row index and the number of elements in the row\n",
    "        active_rows = board.active_rows()\n",
    "        \n",
    "        number_of_elems = board.rows[active_rows[0]]\n",
    "\n",
    "        # Check that the number of elements we want to leave behind is feasible, otherwise\n",
    "        # we pick a single element\n",
    "        return self.__feasability__(self.rules['rule_1'], number_of_elems, active_rows[0])\n",
    "                \n",
    "\n",
    "    # If there are two rows left, where one row has onle 1 elemnt left, leave x elements\n",
    "    # in a random row\n",
    "    def rule_2(self, board):\n",
    "        return self.__find_active_rows__(board, 'rule_2')\n",
    "\n",
    "\n",
    "    # If there are two rows left where both rows have more than 1 element left, leave x elements\n",
    "    # in a random row\n",
    "    def rule_3(self, board):\n",
    "        return self.__find_active_rows__(board, 'rule_3')\n",
    "\n",
    "    def __find_active_rows__(self, board, rule):\n",
    "        active_rows = board.active_rows()\n",
    "        rows_and_elements = []\n",
    "\n",
    "        for index in active_rows:\n",
    "            rows_and_elements.append([index, board.rows[index]])\n",
    "\n",
    "        # Sort the list so the smaller row is first \n",
    "        rows_and_elements.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # Determine if the number of elements we want to leave behind is feasible, otherwise \n",
    "        # pick a single element\n",
    "        chosen_row = rows_and_elements[self.rules[rule][0]]\n",
    "        return self.__feasability__(self.rules[rule][1], chosen_row[1], chosen_row[0])\n",
    "\n",
    "    # If there are more than two rows left, leave x elements in a random row\n",
    "    def rule_4(self, board):\n",
    "        active_rows = board.active_rows()\n",
    "        rows_and_elements = []\n",
    "\n",
    "        for index in active_rows:\n",
    "            rows_and_elements.append([index, board.rows[index]])\n",
    "\n",
    "        chosen_row = random.choice(rows_and_elements)\n",
    "        return self.__feasability__(self.rules['rule_4'], chosen_row[1], chosen_row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_strategy(individual: Rules) -> Callable:\n",
    "    def evolvable(board: Nim) -> Nimply:\n",
    "        active_rows = board.active_rows()\n",
    "        rows_and_elements = []\n",
    "\n",
    "        for index in active_rows:\n",
    "            rows_and_elements.append([index, board.rows[index]])\n",
    "\n",
    "        # Sort the list so the smaller row is first \n",
    "        rows_and_elements.sort(key=lambda x: x[1])\n",
    "        \n",
    "        # If there's only 1 row left\n",
    "        if len(rows_and_elements) == 1:\n",
    "            ply = individual.rule_1(board)\n",
    "        # If there's two rows left\n",
    "        elif len(rows_and_elements) == 2:\n",
    "            # If both active rows have more than 1 element\n",
    "            if rows_and_elements[0][1] > 1 and rows_and_elements[0][1] > 1:\n",
    "                ply = individual.rule_3(board)\n",
    "            else:\n",
    "                ply = individual.rule_2(board)\n",
    "        # If there's more than two rows left\n",
    "        elif len(rows_and_elements) > 2:\n",
    "            ply = individual.rule_4(board)\n",
    "        return ply\n",
    "\n",
    "    return evolvable\n",
    "\n",
    "def pure_random(state: Nim) -> Nimply:\n",
    "    row = random.choice([r for r, c in enumerate(state.rows) if c > 0])\n",
    "    num_objects = random.randint(1, state.rows[row])\n",
    "    return Nimply(row, num_objects)\n",
    "\n",
    "def optimal_strategy(board: Nim) -> Nimply: \n",
    "    *_, X = accumulate(board.rows, xor)\n",
    "\n",
    "    row_count = -1\n",
    "    for row in board.rows:\n",
    "        row_count += 1\n",
    "        if row > 0:\n",
    "            result = X ^ row\n",
    "            if result < row:\n",
    "                return Nimply(row_count, row - result)\n",
    "    return pure_random(board)\n",
    "\n",
    "def stupid(board: Nim) -> Nimply:\n",
    "    return Nimply(board.active_rows()[0], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stupid(board: Nim) -> Nimply:\n",
    "    return Nimply(board.active_rows()[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness(individual, fit_rounds, depth):\n",
    "    fit = []\n",
    "    for opponent in [optimal_strategy, pure_random, stupid]:\n",
    "        wins = 0\n",
    "        strategy = (make_strategy(individual), opponent)\n",
    "        for _ in range(fit_rounds):\n",
    "            wins += gameplay(strategy, depth)\n",
    "        fit.append(wins)\n",
    "    return (fit[0], fit[1], fit[2])\n",
    "\n",
    "def gameplay(strategy, depth):\n",
    "    player = 0\n",
    "    nim = Nim(depth)\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        player = 1 - player\n",
    "    winner = 1 - player\n",
    "    if winner == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def population_init(depth, mu, fit_rounds):\n",
    "    individuals = []\n",
    "    max_leave_nim_size = (depth - 1) * 2\n",
    "\n",
    "    for _ in range(mu):\n",
    "        individual = Rules(Nim(depth), random.randint(0, max_leave_nim_size), \\\n",
    "            (random.randint(0, 1), random.randint(0, max_leave_nim_size)), \\\n",
    "            (random.randint(0,1), random.randint(0, max_leave_nim_size)), \\\n",
    "            random.randint(0, max_leave_nim_size))\n",
    "        fit = fitness(individual, fit_rounds, depth)\n",
    "        individuals.append([fit, individual])\n",
    "    return individuals\n",
    "\n",
    "def tournament(individuals, offspring_size, depth, mut_probability, fit_rounds):\n",
    "    offspring = []\n",
    "    for _ in range(offspring_size):\n",
    "        p1 = max(random.choices(individuals, k=10), key=lambda x: x[0])\n",
    "        p2 = max(random.choices(individuals, k=10), key=lambda x: x[0])\n",
    "\n",
    "        offspring_individual = crossover(p1, p2, depth, mut_probability)\n",
    "        fitness_offspring = fitness(offspring_individual, fit_rounds, depth)\n",
    "\n",
    "        offspring.append((fitness_offspring, offspring_individual))\n",
    "    return offspring\n",
    "\n",
    "def crossover(p1, p2, depth, mut_probability):\n",
    "    # Chose a random amount of rules of the first parent and the rest from the second parent\n",
    "    elements = random.randint(0,4)\n",
    "    n1 = random.sample([i+1 for i in range(4)], elements)\n",
    "    # Pick the rules from the second parent that the first parent didnt pick\n",
    "    n2 = list(set(n1) ^ set([1, 2, 3, 4]))\n",
    "\n",
    "    rules = []\n",
    "    for rule_number in n1:\n",
    "        rules.append((rule_number, 0))\n",
    "    \n",
    "    for rule_number in n2:\n",
    "        rules.append((rule_number, 1))\n",
    "    \n",
    "    parents = []\n",
    "    parents.append(p1[1].get_params())\n",
    "    parents.append(p2[1].get_params())\n",
    "    \n",
    "    rules.sort()\n",
    "\n",
    "    # Create the offspring\n",
    "    offspring = Rules(Nim(depth), parents[rules[0][1]]['rule_1'], parents[rules[1][1]]['rule_2'], \\\n",
    "    parents[rules[2][1]]['rule_3'], parents[rules[3][1]]['rule_4'])\n",
    "\n",
    "    # With a certain probability the offpsring is mutated\n",
    "    if random.random() < mut_probability:\n",
    "        mutate_rule = random.randint(1, 4)\n",
    "        max_leave_nim_size = (depth - 1) * 2\n",
    "        if mutate_rule == 1:\n",
    "            offspring.set_rule_1(random.randint(0, max_leave_nim_size))\n",
    "        elif mutate_rule == 2:\n",
    "            offspring.set_rule_2(random.randint(0, max_leave_nim_size))\n",
    "        elif mutate_rule == 3:\n",
    "            offspring.set_rule_3(random.randint(0, max_leave_nim_size))\n",
    "        elif mutate_rule == 4:\n",
    "            offspring.set_rule_4(random.randint(0, max_leave_nim_size))\n",
    "    return offspring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 20\n",
    "offspring_size = 40\n",
    "fit_rounds = 10\n",
    "mut_probability = 0.1\n",
    "depth = 10\n",
    "\n",
    "individuals = population_init(depth, mu, fit_rounds)\n",
    "individuals.sort(key = lambda x: x[0], reverse=True)\n",
    "old_best = individuals[0][1]\n",
    "\n",
    "for _ in range(500):\n",
    "    offspring = tournament(individuals, offspring_size, depth, mut_probability, fit_rounds)\n",
    "    offspring.sort(key = lambda x: x[0], reverse=True)\n",
    "\n",
    "    individuals = offspring[0:mu]\n",
    "    if _ %50 == 0:\n",
    "        print(\"Progress\")\n",
    "    \n",
    "    if _ %100 == 0:\n",
    "        if individuals[0][1] == old_best:\n",
    "            print('oh oh')\n",
    "            break\n",
    "        else:\n",
    "            old_best = individuals[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual = individuals[0][1]\n",
    "strategy = (make_strategy(individual), pure_random)\n",
    "wins = 0\n",
    "\n",
    "for _ in range(1000):\n",
    "    nim = Nim(15)\n",
    "    #print(f\"status: Initial board  -> {nim}\")\n",
    "    player = 0\n",
    "    while nim:\n",
    "        ply = strategy[player](nim)\n",
    "        nim.nimming(ply)\n",
    "        #print(f\"status: After player {player} -> {nim}\")\n",
    "        player = 1 - player\n",
    "    winner = 1 - player\n",
    "    if winner == 0:\n",
    "        wins += 1\n",
    "print(wins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(individual.get_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = Nim(5)\n",
    "individual = individuals[0][1]\n",
    "strategy = (make_strategy(individual), optimal_strategy)\n",
    "\n",
    "player = 0\n",
    "while nim:\n",
    "    print(nim)\n",
    "    if player == 0:\n",
    "        ply = (int(input()), int(input()))\n",
    "    else:\n",
    "        ply = strategy[1](nim)\n",
    "    nim.nimming(ply)\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "if winner == 0:\n",
    "    print(\"Player 0 won\")\n",
    "else:\n",
    "    print(\"Player 1 won\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_move(nim):\n",
    "    row_count = -1\n",
    "    \n",
    "    for row in nim.rows:\n",
    "        row_count += 1\n",
    "        for i in range(row):\n",
    "            temp_state = deepcopy(nim)\n",
    "            temp_state.nimming((row_count, i+1))\n",
    "            score = evaluate(temp_state, 1)\n",
    "            if score > 0:\n",
    "                return score, (row_count, i+1)\n",
    "    return score, (row_count, i+1)\n",
    "\n",
    "def evaluate(nim, player, alpha=-1, beta=1):\n",
    "    if(not nim):\n",
    "        temp = 1\n",
    "        if player == 0:\n",
    "            temp = -1\n",
    "        return temp\n",
    "\n",
    "    possible_states_list = []\n",
    "    explored_states = set()\n",
    "    row_count = -1\n",
    "    for row in nim.rows:\n",
    "        row_count += 1\n",
    "        if row not in explored_states:\n",
    "            explored_states.add(row)\n",
    "            for i in range(row):\n",
    "                temp_state = deepcopy(nim)\n",
    "                temp_state.nimming((row_count, i+1))\n",
    "                possible_states_list.append(temp_state)\n",
    "\n",
    "    scores = []\n",
    "    for new_state in possible_states_list:\n",
    "        score = evaluate(new_state, 1 - player, alpha, beta)\n",
    "        scores.append(score)\n",
    "        if player == 0:\n",
    "            alpha = max(alpha, score)\n",
    "        else: \n",
    "            beta = min(beta, score)\n",
    "        if beta <= alpha:\n",
    "            break\n",
    "    return (max if player == 0 else min)(scores)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nim = Nim(3)\n",
    "strategy = (best_move)\n",
    "\n",
    "player = 1\n",
    "while nim:\n",
    "    print(nim)\n",
    "    if player == 0:\n",
    "        ply = (int(input()), int(input()))\n",
    "    else:\n",
    "        score, ply = strategy(nim)\n",
    "        print(score)\n",
    "    nim.nimming(ply)\n",
    "    player = 1 - player\n",
    "winner = 1 - player\n",
    "if winner == 0:\n",
    "    print(\"Player 0 won\")\n",
    "else:\n",
    "    print(\"Player 1 won\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Qlearning():\n",
    "\n",
    "    reward = 1\n",
    "    penalty = -1\n",
    "    \n",
    "    def __init__(self, learning_rate, discount_rate, exploring_rate, previous_state = None, previous_move = None):\n",
    "        self.q = {}\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.exploring_rate = exploring_rate\n",
    "        self.previous_state = previous_state\n",
    "        self.previous_move = previous_move\n",
    "\n",
    "    def set_learning_rate(self, learning_rate):\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def set_discount_rate(self, discount_rate):\n",
    "        self.discount_rate = discount_rate\n",
    "\n",
    "    def set_exploring_rate(self, exploring_rate):\n",
    "        self.exploring_rate = exploring_rate\n",
    "\n",
    "    def state_action(self, current_state):\n",
    "        possible_move_list = possible_moves(current_state)\n",
    "\n",
    "        for move in possible_move_list:\n",
    "            if (current_state.rows, move) not in self.q:\n",
    "                self.q[(current_state.rows, move)] = random.uniform(0, 0.01)\n",
    "\n",
    "    def policy(self, current_state):\n",
    "        possible_move_list = possible_moves(current_state)\n",
    "\n",
    "        if random.random() > self.exploring_rate:\n",
    "            # Do not explore, find the best move\n",
    "            chosen_move_val = self.q[(current_state.rows, possible_move_list[0])]\n",
    "            chosen_move = possible_move_list[0]\n",
    "            for move in possible_move_list[1:]:\n",
    "                if self.q[(current_state.rows, move)] > chosen_move_val:\n",
    "                    chosen_move = move\n",
    "                    chosen_move_val = self.q[(current_state.rows, move)]\n",
    "        else: \n",
    "            # We explore\n",
    "            chosen_move = random.sample(possible_move_list, 1)[0]\n",
    "        return chosen_move\n",
    "\n",
    "    def update_policy(self, current_state):\n",
    "        if not current_state:\n",
    "            # Game is finished, update policy about the loss\n",
    "            self.q[(self.previous_state.rows, self.previous_move)] += \\\n",
    "                self.learning_rate * (self.penalty - self.q[(self.previous_state.rows, self.previous_move)])\n",
    "            current_move = self.previous_state = self.previous_move = None\n",
    "        else: \n",
    "            self.state_action(current_state)\n",
    "            current_move = self.policy(current_state)\n",
    "\n",
    "            if self.previous_move != None:\n",
    "                next_state = deepcopy(current_state)\n",
    "                next_state.nimming(current_move)\n",
    "\n",
    "                reward = 0\n",
    "                if not next_state:\n",
    "                    reward = 1\n",
    "\n",
    "                possible_move_list = possible_moves(current_state) \n",
    "                \n",
    "                max_Q_value = self.q[(current_state.rows, possible_move_list[0])]\n",
    "                for move in possible_move_list[1:]:\n",
    "                    if self.q[(current_state.rows, move)] > max_Q_value:\n",
    "                        max_Q_value = self.q[(current_state.rows, move)]\n",
    "\n",
    "                self.q[(self.previous_state.rows, self.previous_move)] += \\\n",
    "                    self.learning_rate * (reward + self.discount_rate * max_Q_value) \\\n",
    "                    - self.q[(self.previous_state.rows, self.previous_move)]\n",
    "\n",
    "            self.previous_state = deepcopy(current_state)\n",
    "            self.previous_move = current_move\n",
    "\n",
    "        return current_move\n",
    "            \n",
    "def train_agent(depth):\n",
    "    iterations = 1000\n",
    "    exploring_increase = 0.3\n",
    "    exploring_decrease = 0.5\n",
    "    exploring_rate = 0.8\n",
    "    agent = Qlearning(0.9, 0.25, exploring_rate)\n",
    "\n",
    "    opponent_strategies = (stupid, pure_random, optimal_strategy)\n",
    "\n",
    "    for opponent in opponent_strategies:\n",
    "        for _ in range(iterations):\n",
    "            play_game(depth, agent, opponent)\n",
    "            exploring_rate -= exploring_decrease/iterations\n",
    "        \n",
    "            if exploring_rate < 0.01:\n",
    "                exploring_rate = 0.01\n",
    "            \n",
    "            agent.set_exploring_rate(exploring_rate)\n",
    "        exploring_rate += exploring_increase\n",
    "        exploring_decrease -= 0.05\n",
    "    return agent\n",
    "\n",
    "def evaluate(agent):\n",
    "    agent.set_exploring_rate(0)\n",
    "    iterations = 100\n",
    "    wins = [0, 0, 0]\n",
    "    i = -1\n",
    "\n",
    "    opponent_strategies = (stupid, pure_random, optimal_strategy)\n",
    "\n",
    "    for opponent in opponent_strategies:\n",
    "        i += 1\n",
    "        for _ in range(iterations):\n",
    "            nim = Nim(5)\n",
    "            player = 0\n",
    "            while nim:\n",
    "                if player == 0:\n",
    "                    try:\n",
    "                        move = agent.policy(nim)\n",
    "                    except KeyError:\n",
    "                        move = agent.update_policy(nim)\n",
    "                else: \n",
    "                    move = opponent(nim)\n",
    "                nim.nimming(move)\n",
    "                player = 1 - player\n",
    "            wins[i] += player #winrate\n",
    "    return wins\n",
    "\n",
    "def possible_moves(nim):\n",
    "    possible_moves_list = []\n",
    "    row_count = -1\n",
    "    for row in nim.rows:\n",
    "        row_count += 1\n",
    "        for i in range(row):\n",
    "            possible_moves_list.append((row_count, i+1))\n",
    "    return possible_moves_list\n",
    "\n",
    "def play_game(depth, agent, opponent):\n",
    "    nim = Nim(depth)\n",
    "    player = 0\n",
    "\n",
    "    while True: \n",
    "        if len(nim.active_rows()) == 0:\n",
    "            return 1-player\n",
    "        if player == 0:\n",
    "            move = agent.update_policy(nim)\n",
    "        else: \n",
    "            move = opponent(nim)\n",
    "        nim.nimming(move)\n",
    "        player = 1 - player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.050000000000030465\n",
      "[100, 72, 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'player = 0\\nwhile nim:\\n    print(nim)\\n    if player == 0:\\n        ply = (int(input()), int(input()))\\n    else:\\n        ply = agent.update_policy(nim)\\n    nim.nimming(ply)\\n    player = 1 - player\\nwinner = 1 - player'"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent = train_agent(5)\n",
    "print(agent.exploring_rate)\n",
    "\n",
    "wins = evaluate(agent)\n",
    "\n",
    "print(wins)\n",
    "\n",
    "'''player = 0\n",
    "while nim:\n",
    "    print(nim)\n",
    "    if player == 0:\n",
    "        ply = (int(input()), int(input()))\n",
    "    else:\n",
    "        ply = agent.update_policy(nim)\n",
    "    nim.nimming(ply)\n",
    "    player = 1 - player\n",
    "winner = 1 - player'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c96d11993e7d280684d06cb23e31751296310acc16de0209c242ec6c1aebc7f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
